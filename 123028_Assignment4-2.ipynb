{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1aszFtaDrChT6i7bPGlXzVLLC4KnWP1oq","authorship_tag":"ABX9TyO5nVvqeeLDoBb7PKGGn0YM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"6224a41fccb24fdcbb72b76a3981bbe0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e8bcc01caed437c9e21ee41740f94bb","IPY_MODEL_9763441f91ce4545ba6b8834782f6a51","IPY_MODEL_8b49ec301d394ce1b96b9c1f1a64350c"],"layout":"IPY_MODEL_7a1b4fad0a5c484887dc30e696a17c41"}},"5e8bcc01caed437c9e21ee41740f94bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1406a9c3e8f14b76bf53490b4e0a4240","placeholder":"​","style":"IPY_MODEL_1ccd3ec569414d83a0b436698f4f9672","value":"100%"}},"9763441f91ce4545ba6b8834782f6a51":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e21c50e0ad14954bd7f78ced73120c3","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_610793bcb3294b1ea1146eaa2ef4302c","value":2}},"8b49ec301d394ce1b96b9c1f1a64350c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44011c7ee7874f478128a295bd390fd0","placeholder":"​","style":"IPY_MODEL_8f5add07831f420fabb8b6902e7f4e07","value":" 2/2 [00:00&lt;00:00, 100.53it/s]"}},"7a1b4fad0a5c484887dc30e696a17c41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1406a9c3e8f14b76bf53490b4e0a4240":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ccd3ec569414d83a0b436698f4f9672":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e21c50e0ad14954bd7f78ced73120c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"610793bcb3294b1ea1146eaa2ef4302c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44011c7ee7874f478128a295bd390fd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f5add07831f420fabb8b6902e7f4e07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9N39RoP7I19b","executionInfo":{"status":"ok","timestamp":1682593873066,"user_tz":-420,"elapsed":2635,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"0d06defa-fa36-4d00-e0cf-0d55176a0005"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch, torchdata, torchtext\n","from torch import nn\n","\n","import time\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","#make our work comparable if restarted the kernel\n","SEED = 1234\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","source":["\n","torch.cuda.get_device_name(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"3bZu6ZaaKWYS","executionInfo":{"status":"ok","timestamp":1682593873068,"user_tz":-420,"elapsed":71,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"82b56ecc-2c3d-4e59-9e2d-06da34ff5e57"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla T4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["torch.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"1M4zCWUxKYYR","executionInfo":{"status":"ok","timestamp":1682593873126,"user_tz":-420,"elapsed":125,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"1f5d79be-10bb-490d-e0c0-14dd682d5439"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.0.0+cu118'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["torchtext.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"RlNStDqIKby6","executionInfo":{"status":"ok","timestamp":1682593873127,"user_tz":-420,"elapsed":121,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"45f6154f-3c51-4939-dbaf-8c0b38a2c80f"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0.15.1+cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# 1. ETL: Loading the dataset"],"metadata":{"id":"JH9Jjd6vK6dO"}},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"krc4dVGWNiKF","executionInfo":{"status":"ok","timestamp":1682593877882,"user_tz":-420,"elapsed":4873,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"e978be96-7d2e-4915-841d-5fe769c686ee"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.11.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.14.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"]}]},{"cell_type":"code","source":["!pip install portalocker\n","!pip install portalocker>=2.0.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tHx3GC0eOLTb","executionInfo":{"status":"ok","timestamp":1682593882992,"user_tz":-420,"elapsed":5124,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"5bd38273-5628-48bb-8576-3a3b86d2312f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.9/dist-packages (2.7.0)\n"]}]},{"cell_type":"code","source":["import datasets \n","dataset = datasets.load_dataset(\"codeparrot/github-jupyter-code-to-text\")\n","print(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":260,"referenced_widgets":["6224a41fccb24fdcbb72b76a3981bbe0","5e8bcc01caed437c9e21ee41740f94bb","9763441f91ce4545ba6b8834782f6a51","8b49ec301d394ce1b96b9c1f1a64350c","7a1b4fad0a5c484887dc30e696a17c41","1406a9c3e8f14b76bf53490b4e0a4240","1ccd3ec569414d83a0b436698f4f9672","8e21c50e0ad14954bd7f78ced73120c3","610793bcb3294b1ea1146eaa2ef4302c","44011c7ee7874f478128a295bd390fd0","8f5add07831f420fabb8b6902e7f4e07"]},"id":"uVVAJE2zKd0e","executionInfo":{"status":"ok","timestamp":1682593885509,"user_tz":-420,"elapsed":2544,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"ef08e150-caec-4cfb-99c0-f74d06ca3de2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/codeparrot___parquet/codeparrot--github-jupyter-code-to-text-cf9b56d996fd17e1/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6224a41fccb24fdcbb72b76a3981bbe0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['repo_name', 'path', 'license', 'content'],\n","        num_rows: 47452\n","    })\n","    test: Dataset({\n","        features: ['repo_name', 'path', 'license', 'content'],\n","        num_rows: 11864\n","    })\n","})\n"]}]},{"cell_type":"markdown","source":["# 2. EDA - simple investigation"],"metadata":{"id":"DZhOwpN6SW4H"}},{"cell_type":"code","source":["total_train_dataset =[]\n","total_test_dataset = []\n","for text in dataset['train']['content']:\n","  for split in text.split('\\n'):\n","    if split != \"\":\n","      total_train_dataset.append(split)\n","\n","for text in dataset['test']['content']:\n","  for split in text.split('\\n'):\n","    if split != \"\":\n","      total_test_dataset.append(split)\n","\n","print(len(total_train_dataset),len(total_test_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_EVSo4wOV04","executionInfo":{"status":"ok","timestamp":1682593891103,"user_tz":-420,"elapsed":5620,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"62f83f4a-909c-4e28-a829-cee318c2f9cd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["11367363 2875424\n"]}]},{"cell_type":"markdown","source":["# 3. Preprocessing + 4. Embeddings"],"metadata":{"id":"KVqfTrPNSOmr"}},{"cell_type":"code","source":["from torchtext.data.utils import get_tokenizer\n","def yield_tokens(data_iter):\n","    for text in data_iter:\n","        yield tokenizer(text)\n","\n","tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n","\n","tokenized_train = yield_tokens(total_train_dataset[:int(len(total_train_dataset)/100)])\n","tokenized_test = yield_tokens(total_test_dataset[:int(len(total_test_dataset)/100)])"],"metadata":{"id":"lccQ6xUmQPkD","executionInfo":{"status":"ok","timestamp":1682593900595,"user_tz":-420,"elapsed":9497,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding"],"metadata":{"id":"h4TUw3QtRT2T","executionInfo":{"status":"ok","timestamp":1682593900601,"user_tz":-420,"elapsed":26,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from spacy.lang.en.stop_words import STOP_WORDS\n","import spacy\n","import re\n","\n","nlp = spacy.load('en_core_web_sm')\n","\n","def preprocessing(sentence):\n","    \n","    sentence = re.sub(\"<[^>]*>\", \"\", sentence)\n","    sentence = re.sub(\"[^\\x00-\\x7F]+\", \"\", sentence) \n","\n","    stopwords = list(STOP_WORDS)\n","    doc = nlp(sentence)\n","    cleaned_tokens = []\n","    \n","    for token in doc:\n","        if token.text not in stopwords and token.pos_ != 'PUNCT' and token.pos_ != 'SPACE' and \\\n","            token.pos_ != 'SYM' and token.pos_!= 'X':\n","                cleaned_tokens.append(token.lemma_.lower().strip())\n","                \n","    return \" \".join(cleaned_tokens)"],"metadata":{"id":"oTWFwNizRvZn","executionInfo":{"status":"ok","timestamp":1682593900601,"user_tz":-420,"elapsed":24,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from torchtext.vocab import build_vocab_from_iterator\n","def yield_tokens(data_iter):\n","    for text in data_iter:\n","        yield tokenizer(preprocessing(text))\n","\n","vocab = build_vocab_from_iterator(yield_tokens(total_train_dataset[:int(len(total_test_dataset)/100)]), min_freq=5) \n","vocab.insert_token('<unk>', 0)           \n","vocab.insert_token('<eos>', 1)            \n","vocab.set_default_index(vocab['<unk>'])   \n","print('Vocab Size',len(vocab))                         \n","print(vocab.get_itos()[:10]) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IiW9yqzxR0SI","executionInfo":{"status":"ok","timestamp":1682594059916,"user_tz":-420,"elapsed":159338,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"4f4e3d90-e6d6-4327-ff9b-07abd7337604"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocab Size 2754\n","['<unk>', '<eos>', '=', '#', 'explanation', 'end', \"'\", 'import', 'datum', 'property']\n"]}]},{"cell_type":"code","source":["def get_data(dataset, vocab, batch_size):\n","    data = []                                                   \n","    for example in dataset:       \n","        #appends eos so we know it ends....so model learn how to end...                             \n","        tokens = example.append('<eos>') #end of sentence\n","        #numericalize          \n","        tokens = [vocab[token] for token in example] \n","        data.extend(tokens)                                    \n","    data = torch.LongTensor(data)                                 \n","    num_batches = data.shape[0] // batch_size \n","    data = data[:num_batches * batch_size]                       \n","    data = data.view(batch_size, num_batches)        \n","    return data"],"metadata":{"id":"_cU2sDX2Se2S","executionInfo":{"status":"ok","timestamp":1682594059917,"user_tz":-420,"elapsed":22,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["batch_size = 128\n","train_loader = get_data(tokenized_train, vocab, batch_size)\n","valid_loader = get_data(tokenized_test, vocab, batch_size)"],"metadata":{"id":"imPPx0NTSl2C","executionInfo":{"status":"ok","timestamp":1682594070101,"user_tz":-420,"elapsed":10205,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["train_loader.shape, valid_loader.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bHFhUWI9UBhr","executionInfo":{"status":"ok","timestamp":1682594070102,"user_tz":-420,"elapsed":33,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"0654aabc-2227-4806-c9fa-d65059b1f478"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([128, 8296]), torch.Size([128, 2204]))"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["# 6. Design the model"],"metadata":{"id":"FapZ6eAjTU0L"}},{"cell_type":"code","source":["import torch.nn as nn\n","import math\n","class LSTM(nn.Module):\n","    def __init__(self, vocab_size, emb_dim, hid_dim, num_layers, dropout_rate):\n","                \n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.hid_dim = hid_dim\n","        self.emb_dim = emb_dim\n","\n","        self.embedding = nn.Embedding(vocab_size, emb_dim)\n","        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers=num_layers, \n","                    dropout=dropout_rate, batch_first=True)\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.fc = nn.Linear(hid_dim, vocab_size)\n","        \n","        self.init_weights()\n","        \n","    def init_weights(self):\n","        init_range_emb = 0.1\n","        init_range_other = 1/math.sqrt(self.hid_dim)\n","        self.embedding.weight.data.uniform_(-init_range_emb, init_range_emb)\n","        self.fc.weight.data.uniform_(-init_range_other, init_range_other)\n","        self.fc.bias.data.zero_()\n","        for i in range(self.num_layers):\n","            self.lstm.all_weights[i][0] = torch.FloatTensor(self.emb_dim,\n","                    self.hid_dim).uniform_(-init_range_other, init_range_other) \n","            self.lstm.all_weights[i][1] = torch.FloatTensor(self.hid_dim, \n","                    self.hid_dim).uniform_(-init_range_other, init_range_other) \n","\n","    def init_hidden(self, batch_size, device):\n","        hidden = torch.zeros(self.num_layers, batch_size, self.hid_dim).to(device)\n","        cell   = torch.zeros(self.num_layers, batch_size, self.hid_dim).to(device)\n","        return hidden, cell\n","    \n","    def detach_hidden(self, hidden):\n","        hidden, cell = hidden\n","        hidden = hidden.detach()\n","        cell = cell.detach()\n","        return hidden, cell\n","\n","    def forward(self, src, hidden):\n","        #src: [batch size, seq len]\n","        embedding = self.dropout(self.embedding(src))\n","        #embedding: [batch size, seq len, emb_dim]\n","        output, hidden = self.lstm(embedding, hidden)      \n","        #output: [batch size, seq len, hid_dim]\n","        #hidden = h, c = [num_layers * direction, seq len, hid_dim)\n","        output = self.dropout(output) \n","        prediction = self.fc(output)\n","        #prediction: [batch size, seq_len, vocab size]\n","        return prediction, hidden"],"metadata":{"id":"nMiEr4hkTQYh","executionInfo":{"status":"ok","timestamp":1682594070106,"user_tz":-420,"elapsed":31,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# 7. Training"],"metadata":{"id":"3bS1fvXQUP8t"}},{"cell_type":"code","source":["def initialize_weights(m):\n","    if isinstance(m, nn.Linear):\n","        nn.init.xavier_normal_(m.weight)\n","        nn.init.zeros_(m.bias)\n","    elif isinstance(m, nn.LSTM):\n","        for name, param in m.named_parameters():\n","            if 'bias' in name:\n","                nn.init.zeros_(param)\n","            elif 'weight' in name:\n","                nn.init.orthogonal_(param)"],"metadata":{"id":"kXaBP4XaUH9b","executionInfo":{"status":"ok","timestamp":1682594070107,"user_tz":-420,"elapsed":32,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aaqboGMfUzv0","executionInfo":{"status":"ok","timestamp":1682594070108,"user_tz":-420,"elapsed":32,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","vocab_size = len(vocab)\n","emb_dim = 1024                # 400 in the paper\n","hid_dim = 1024                # 1150 in the paper\n","num_layers = 2                # 3 in the paper\n","dropout_rate = 0.65              \n","lr = 1e-3  \n","\n","model = LSTM(vocab_size, emb_dim, hid_dim, num_layers, dropout_rate).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","criterion = nn.CrossEntropyLoss()\n","num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f'The model has {num_params:,} trainable parameters')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LMEwHYBWUUcK","executionInfo":{"status":"ok","timestamp":1682594123338,"user_tz":-420,"elapsed":24,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"edece9c3-4cd9-4a9b-8dbb-b94af551858b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 22,436,546 trainable parameters\n"]}]},{"cell_type":"code","source":["def count_parameters(model):\n","    params = [p.numel() for p in model.parameters() if p.requires_grad]\n","    for item in params:\n","        print(f'{item:>6}')\n","    print(f'______\\n{sum(params):>6}')\n","    \n","count_parameters(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MvZTAmATUYiH","executionInfo":{"status":"ok","timestamp":1682594123339,"user_tz":-420,"elapsed":15,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"d42444eb-71b9-450c-b40d-56200eda9356"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["2820096\n","4194304\n","4194304\n","  4096\n","  4096\n","4194304\n","4194304\n","  4096\n","  4096\n","2820096\n","  2754\n","______\n","22436546\n"]}]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","lr=1e-3\n","\n","#training hyperparameters\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","criterion = nn.CrossEntropyLoss() #combine softmax with cross entropy"],"metadata":{"id":"YPPc-JC7VlPI","executionInfo":{"status":"ok","timestamp":1682594123340,"user_tz":-420,"elapsed":11,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def accuracy(preds, y):\n","    \n","    predicted = torch.max(preds.data, 1)[1]\n","    batch_corr = (predicted == y).sum()\n","    acc = batch_corr / len(y)\n","    \n","    return acc"],"metadata":{"id":"E9Vfmn5PVt90","executionInfo":{"status":"ok","timestamp":1682594123340,"user_tz":-420,"elapsed":11,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def get_batch(data, seq_len, idx):\n","    #data #[batch size, bunch of tokens]\n","    src    = data[:, idx:idx+seq_len]                   \n","    target = data[:, idx+1:idx+seq_len+1]  #target simply is ahead of src by 1            \n","    return src, target"],"metadata":{"id":"PowzDOF9XFGR","executionInfo":{"status":"ok","timestamp":1682594123341,"user_tz":-420,"elapsed":11,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","def train(model, data, optimizer, criterion, batch_size, seq_len, clip, device):\n","    \n","    epoch_loss = 0\n","    model.train()\n","\n","    num_batches = data.shape[-1]\n","    data = data[:, :num_batches - (num_batches -1) % seq_len] \n","    num_batches = data.shape[-1]\n","    \n","    hidden = model.init_hidden(batch_size, device)\n","    \n","    for idx in tqdm(range(0, num_batches - 1, seq_len), desc='Training: ',leave=False):\n","        optimizer.zero_grad()\n","\n","        hidden = model.detach_hidden(hidden)\n","\n","        src, target = get_batch(data, seq_len, idx) #src, target: [batch size, seq len]\n","        src, target = src.to(device), target.to(device)\n","        batch_size = src.shape[0]\n","        prediction, hidden = model(src, hidden)               \n","\n","        #need to reshape because criterion expects pred to be 2d and target to be 1d\n","        prediction = prediction.reshape(batch_size * seq_len, -1)  #prediction: [batch size * seq len, vocab size]  \n","        target = target.reshape(-1)\n","        loss = criterion(prediction, target)\n","        \n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        epoch_loss += loss.item() * seq_len\n","    return epoch_loss / num_batches"],"metadata":{"id":"sk-zZxQwVvoC","executionInfo":{"status":"ok","timestamp":1682594124767,"user_tz":-420,"elapsed":13,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, data, criterion, batch_size, seq_len, device):\n","\n","    epoch_loss = 0\n","    model.eval()\n","    num_batches = data.shape[-1]\n","    data = data[:, :num_batches - (num_batches -1) % seq_len]\n","    num_batches = data.shape[-1]\n","\n","    hidden = model.init_hidden(batch_size, device)\n","\n","    with torch.no_grad():\n","        for idx in range(0, num_batches - 1, seq_len):\n","            hidden = model.detach_hidden(hidden)\n","            src, target = get_batch(data, seq_len, idx)\n","            src, target = src.to(device), target.to(device)\n","            batch_size= src.shape[0]\n","\n","            prediction, hidden = model(src, hidden)\n","            prediction = prediction.reshape(batch_size * seq_len, -1)\n","            target = target.reshape(-1)\n","\n","            loss = criterion(prediction, target)\n","            epoch_loss += loss.item() * seq_len\n","    return epoch_loss / num_batches"],"metadata":{"id":"XXEEbZL1VyIb","executionInfo":{"status":"ok","timestamp":1682594125984,"user_tz":-420,"elapsed":7,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["train_loader_length = len(list(iter(train_loader)))\n","val_loader_length   = len(list(iter(valid_loader)))"],"metadata":{"id":"cawvxcbBV1Ao","executionInfo":{"status":"ok","timestamp":1682594128869,"user_tz":-420,"elapsed":8,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"hqGYB0mHV9Yx","executionInfo":{"status":"ok","timestamp":1682594131920,"user_tz":-420,"elapsed":17,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["import math\n","n_epochs = 20\n","seq_len  = 30 #<----decoding length\n","clip    = 0.25\n","\n","lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(n_epochs):\n","    train_loss = train(model, train_loader, optimizer, criterion, \n","                batch_size, seq_len, clip, device)\n","    valid_loss = evaluate(model, valid_loader, criterion, batch_size, \n","                seq_len, device)\n","\n","    lr_scheduler.step(valid_loss)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'autoFilled.pt')\n","    print(f'\\tepoch: {epoch+1}')\n","    print(f'\\tTrain exp loss: {math.exp(train_loss):.3f}')\n","    print(f'\\tValid exp loss: {math.exp(valid_loss):.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZ0nq9mNWBVm","executionInfo":{"status":"ok","timestamp":1682595153289,"user_tz":-420,"elapsed":876282,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"2f95af64-301b-4e99-bac7-7fba5f0dcde3"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 1\n","\tTrain exp loss: 9.882\n","\tValid exp loss: 11.207\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 2\n","\tTrain exp loss: 8.902\n","\tValid exp loss: 9.699\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 3\n","\tTrain exp loss: 8.050\n","\tValid exp loss: 9.172\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 4\n","\tTrain exp loss: 7.601\n","\tValid exp loss: 8.847\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 5\n","\tTrain exp loss: 7.225\n","\tValid exp loss: 8.470\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 6\n","\tTrain exp loss: 6.941\n","\tValid exp loss: 8.331\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 7\n","\tTrain exp loss: 6.742\n","\tValid exp loss: 8.297\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 8\n","\tTrain exp loss: 6.540\n","\tValid exp loss: 8.031\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 9\n","\tTrain exp loss: 6.369\n","\tValid exp loss: 8.032\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 10\n","\tTrain exp loss: 6.147\n","\tValid exp loss: 7.960\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 11\n","\tTrain exp loss: 5.985\n","\tValid exp loss: 7.851\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 12\n","\tTrain exp loss: 5.838\n","\tValid exp loss: 7.854\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 13\n","\tTrain exp loss: 5.720\n","\tValid exp loss: 7.791\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 14\n","\tTrain exp loss: 5.637\n","\tValid exp loss: 7.736\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 15\n","\tTrain exp loss: 5.574\n","\tValid exp loss: 7.665\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 16\n","\tTrain exp loss: 5.510\n","\tValid exp loss: 7.689\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 17\n","\tTrain exp loss: 5.451\n","\tValid exp loss: 7.646\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 18\n","\tTrain exp loss: 5.405\n","\tValid exp loss: 7.638\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 19\n","\tTrain exp loss: 5.375\n","\tValid exp loss: 7.649\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tepoch: 20\n","\tTrain exp loss: 5.344\n","\tValid exp loss: 7.633\n"]}]},{"cell_type":"code","source":["def generate(prompt, max_seq_len, temperature, model, tokenizer, vocab, device, seed=None):\n","    if seed is not None:\n","        torch.manual_seed(seed)\n","    model.eval()\n","    tokens = tokenizer(prompt)\n","    indices = [vocab[t] for t in tokens]\n","    batch_size = 1\n","    hidden = model.init_hidden(batch_size, device)\n","    with torch.no_grad():\n","        for i in range(max_seq_len):\n","            src = torch.LongTensor([indices]).to(device)\n","            prediction, hidden = model(src, hidden)\n","            \n","            #prediction: [batch size, seq len, vocab size]\n","            #prediction[:, -1]: [batch size, vocab size] #probability of last vocab\n","            \n","            probs = torch.softmax(prediction[:, -1] / temperature, dim=-1)  \n","            prediction = torch.multinomial(probs, num_samples=1).item()    \n","            \n","            while prediction == vocab['<unk>']: #if it is unk, we sample again\n","                prediction = torch.multinomial(probs, num_samples=1).item()\n","\n","            if prediction == vocab['<eos>']:    #if it is eos, we stop\n","                break\n","\n","            indices.append(prediction) #autoregressive, thus output becomes input\n","\n","    itos = vocab.get_itos()\n","    tokens = [itos[i] for i in indices]\n","    return tokens"],"metadata":{"id":"unqq2c0vWFKm","executionInfo":{"status":"ok","timestamp":1682595153290,"user_tz":-420,"elapsed":39,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["prompt = 'import n'\n","max_seq_len = 30\n","seed = 0\n","            #superdiverse   more diverse\n","temperatures = [0.5, 0.7, 0.75, 0.8, 1.0] \n","#sample from this distribution higher probability will get more change\n","for temperature in temperatures:\n","    generation = generate(prompt, max_seq_len, temperature, model, tokenizer, \n","                          vocab, device, seed)\n","    print(str(temperature)+'\\n'+' '.join(generation)+'\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJrJaZ07erAI","executionInfo":{"status":"ok","timestamp":1682595167677,"user_tz":-420,"elapsed":6,"user":{"displayName":"Tan Santativongchai","userId":"04436938193154869450"}},"outputId":"12cabd85-dc5c-478e-c944-3c98a42d4e90"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5\n","import n\n","\n","0.7\n","import n\n","\n","0.75\n","import n\n","\n","0.8\n","import n\n","\n","1.0\n","import n shape\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pAzZMzfveuYG"},"execution_count":null,"outputs":[]}]}